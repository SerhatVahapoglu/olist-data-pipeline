# ğŸš€ Olist E-Commerce End-to-End Data Pipeline

Bu proje, Brezilya'nÄ±n en bÃ¼yÃ¼k e-ticaret platformlarÄ±ndan biri olan Olist'in verilerini kullanarak oluÅŸturulmuÅŸ, uÃ§tan uca bir **Data Engineering** projesidir.

## ğŸ—ï¸ Mimari YapÄ±
Proje, modern veri yÄ±ÄŸÄ±nÄ± (Modern Data Stack) prensiplerine gÃ¶re inÅŸa edilmiÅŸtir:
* **Orchestration:** Apache Airflow (Docker Ã¼zerinden)
* **Data Lakehouse:** Databricks (Medallion Architecture: Bronze, Silver, Gold)
* **Storage & Governance:** Unity Catalog & Databricks Volumes
* **Analytics:** Databricks SQL Dashboards
* **Version Control:** GitHub Integration (CI/CD Ready)

## ğŸ“Š Analytics Dashboard
![Executive Dashboard](./dashboard_preview.png)
*Proje kapsamÄ±nda oluÅŸturulan yÃ¶netici Ã¶zeti paneli.*

## âš™ï¸ Pipeline AkÄ±ÅŸÄ±
1.  **Ingestion (Bronze):** Ham CSV verileri Unity Catalog Volumes Ã¼zerinden Spark ile okunur.
2.  **Transformation (Silver):** Veri temizleme, tip dÃ¶nÃ¼ÅŸÃ¼mleri ve JOIN iÅŸlemleri yapÄ±lÄ±r.
3.  **Aggregation (Gold):** Ä°ÅŸ birimleri iÃ§in Ã¶zet tablolar (Åehir bazlÄ± satÄ±ÅŸlar, zaman serisi analizi) hazÄ±rlanÄ±r.
4.  **Quality Checks:** Her aÅŸamada veri tutarlÄ±lÄ±ÄŸÄ± testleri uygulanÄ±r.

## ğŸ› ï¸ Kurulum
1. `docker-compose up` ile Airflow'u ayaÄŸa kaldÄ±rÄ±n.
2. Databricks Ã¼zerinde `config/project_config` ayarlarÄ±nÄ± yapÄ±n.
3. DAG'larÄ± tetikleyerek pipeline'Ä± Ã§alÄ±ÅŸtÄ±rÄ±n.
